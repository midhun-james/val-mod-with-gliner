{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midhun-james/val-mod-with-gliner/blob/main/gliner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gliner rapidfuzz"
      ],
      "metadata": {
        "id": "N-lTwpQc3Chi",
        "outputId": "15238574-21b8-46fb-fc46-7620e945cfce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gliner\n",
            "  Downloading gliner-0.2.19-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.11/dist-packages (from gliner) (4.51.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.4 in /usr/local/lib/python3.11/dist-packages (from gliner) (0.31.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gliner) (4.67.1)\n",
            "Collecting onnxruntime (from gliner)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from gliner) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.4->gliner) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->gliner)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->gliner) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.38.2->gliner) (0.5.3)\n",
            "Collecting coloredlogs (from onnxruntime->gliner)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (5.29.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->gliner)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->gliner) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.4->gliner) (2025.4.26)\n",
            "Downloading gliner-0.2.19-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12, gliner\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 gliner-0.2.19 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install polars"
      ],
      "metadata": {
        "id": "FwBwlyy_4bZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import time\n",
        "import gzip\n",
        "import sqlite3\n",
        "import sqlparse\n",
        "from sqlparse.sql import Token\n",
        "from sqlparse.tokens import Literal,String\n",
        "from datetime import datetime\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import polars as pl\n",
        "from openpyxl import load_workbook\n",
        "from gliner import GLiNER\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "class DataMaskerCSV:\n",
        "    def __init__(self,file_path):\n",
        "        # self.entity_column_map={\n",
        "        #                 'names': 'names',\n",
        "        #                 'emails': 'emails',\n",
        "        #                 'phone': 'phone',\n",
        "        #                 'credit': 'credit',\n",
        "        #                 'url': 'url',\n",
        "        #                 'location': 'location',\n",
        "        #                 'company': 'company',\n",
        "        #             }\n",
        "        self.file_path=file_path\n",
        "        self.base_name=os.path.splitext(os.path.basename(self.file_path))[0]\n",
        "        self.output_dir=self.base_name\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        self.entity_column_map={\n",
        "                'name': 'company',\n",
        "                'domain': 'url',\n",
        "                'locality': 'location',\n",
        "                }\n",
        "        self.model=GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
        "        self.sensitive_columns = self.entity_column_map.keys()\n",
        "        start=time.time()\n",
        "        self.faker_data_path= 'faker_dataset_v3.json.gz'\n",
        "        with gzip.open(self.faker_data_path, 'rt',encoding='utf-8') as f:\n",
        "            faker_list = json.load(f)\n",
        "        end=time.time()\n",
        "        print(f\"⏳ Faker data loaded in {end-start:.6f} seconds\")\n",
        "        self.faker_data = {}\n",
        "        for d in faker_list:\n",
        "            self.faker_data.update(d)\n",
        "        self.domain_pool= self.faker_data['url']\n",
        "        self.forward_mapping = defaultdict(dict)\n",
        "        self.backward_mapping = defaultdict(dict)\n",
        "        self.mapping= defaultdict(dict)\n",
        "        self.fake_data_index = defaultdict(int)\n",
        "        self.used_fakes = defaultdict(set)\n",
        "        self.used_urls = set()\n",
        "        self.url_extensions =  [\n",
        "                                    \".com\", \".net\", \".org\", \".edu\", \".gov\", \".co\", \".us\", \".uk\", \".in\", \".ru\",\n",
        "                                    \".jp\", \".cn\", \".de\", \".fr\", \".it\", \".nl\", \".es\", \".br\", \".au\", \".ca\",\n",
        "                                    \".ch\", \".se\", \".no\", \".za\", \".mx\", \".ar\", \".be\", \".kr\", \".pl\", \".tr\",\n",
        "                                    \".ua\", \".ir\", \".sa\", \".ae\", \".my\", \".sg\", \".hk\", \".tw\", \".nz\", \".id\",\n",
        "                                    \".th\", \".ph\", \".vn\", \".bd\", \".lk\", \".np\", \".pk\", \".cz\", \".gr\", \".hu\",\n",
        "                                    \".fi\", \".dk\", \".il\", \".ie\", \".pt\", \".sk\", \".si\", \".ro\", \".bg\", \".rs\",\n",
        "                                    \".lt\", \".lv\", \".ee\", \".hr\", \".ba\", \".md\", \".ge\", \".kz\", \".by\", \".tm\",\n",
        "                                    \".uz\", \".af\", \".qa\", \".om\", \".kw\", \".bh\", \".ye\", \".jo\", \".lb\", \".sy\",\n",
        "                                    \".iq\", \".ps\", \".az\", \".am\", \".kg\", \".mn\", \".bt\", \".mv\", \".mm\", \".kh\",\n",
        "                                    \".la\", \".tl\", \".sb\", \".fj\", \".pg\", \".to\", \".tv\", \".ws\", \".fm\", \".ki\"\n",
        "                                ]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def time_it(func):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = time.time()\n",
        "            result = func(*args, **kwargs)\n",
        "            end = time.time()\n",
        "            print(f'\\n⏳ Execution time {func.__name__}: {end-start:.6f} seconds')\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "    @time_it\n",
        "    def csv_extraction(self):\n",
        "\n",
        "        output_csv_path=os.path.join(self.output_dir,f'new_{self.base_name}.csv')\n",
        "        if self.file_path.endswith('.xlsx'):\n",
        "            sheet_names = pd.ExcelFile(self.file_path).sheet_names\n",
        "            df=pl.read_excel(self.file_path,engine='calamine',sheet_name=sheet_names)\n",
        "            combined_df = pl.concat(df.values(), how=\"diagonal\")\n",
        "            combined_df.write_csv('intermediate.csv')\n",
        "            self.file_path='intermediate.csv'\n",
        "\n",
        "        all_data={}\n",
        "        for col in self.sensitive_columns:\n",
        "            entity=self.entity_column_map.get(col)\n",
        "            if entity:\n",
        "                all_data.setdefault(entity, [])\n",
        "        df=pd.read_csv(self.file_path)\n",
        "        for col in self.sensitive_columns:\n",
        "            if col in df.columns:\n",
        "                entity=self.entity_column_map.get(col)\n",
        "                if entity:\n",
        "                    values=df[col].dropna().to_list()\n",
        "                    all_data[entity].extend(values)\n",
        "                else:\n",
        "                    entity=self.entity_column_map.get(col.lower())\n",
        "                    if entity:\n",
        "                        all_data[entity].extend([None]*len(df))\n",
        "        max_len=max([len(v) for v in all_data.values()])\n",
        "        for entity in all_data:\n",
        "            all_data[entity].extend([None]*(max_len-len(all_data[entity])))\n",
        "        final_df=pd.DataFrame(all_data)\n",
        "        final_df.to_csv(output_csv_path,index=False)\n",
        "\n",
        "        if self.file_path == 'intermediate.csv': os.remove(self.file_path)\n",
        "        self.anonymize_csv(output_csv_path)\n",
        "\n",
        "    def _get_fake_value(self, entity, original_value):\n",
        "        \"\"\"Return consistent fake value for an original value.\"\"\"\n",
        "        col_key =  entity  # default fallback if column not passed\n",
        "\n",
        "\n",
        "        if original_value in self.forward_mapping[col_key]:\n",
        "            return self.forward_mapping[col_key][original_value]\n",
        "        if entity =='url':\n",
        "            while True:\n",
        "                domain1,domain2=random.sample(self.domain_pool,2)\n",
        "                fake_value=f\"https://{domain1.lower()}.{domain2.lower()}.co\"\n",
        "                if fake_value not in self.used_fakes[entity]:\n",
        "                    break\n",
        "            self.used_fakes[entity].add(fake_value)\n",
        "            self.forward_mapping[col_key][original_value] = fake_value\n",
        "            self.backward_mapping[col_key][fake_value] = original_value\n",
        "            return fake_value\n",
        "\n",
        "        while self.fake_data_index[entity] < len(self.faker_data[entity]):\n",
        "            fake_value = self.faker_data[entity][self.fake_data_index[entity]]\n",
        "            self.fake_data_index[entity] += 1\n",
        "\n",
        "            if fake_value not in self.used_fakes[entity]:\n",
        "                self.used_fakes[entity].add(fake_value)\n",
        "                self.forward_mapping[col_key][original_value] = fake_value\n",
        "                self.backward_mapping[col_key][fake_value] = original_value\n",
        "                return fake_value\n",
        "\n",
        "        counter=1\n",
        "        base_fake_value=original_value\n",
        "        while True:\n",
        "            fallback_value= self.modify_fake_value(entity, base_fake_value,  counter=counter)\n",
        "            if fallback_value not in self.used_fakes[entity]:\n",
        "                self.used_fakes[entity].add(fallback_value)\n",
        "                self.forward_mapping[col_key][original_value] = fallback_value\n",
        "                self.backward_mapping[col_key][fallback_value] = original_value\n",
        "                return fallback_value\n",
        "            counter+=1\n",
        "\n",
        "\n",
        "    def modify_fake_value(self,entity,original_value,counter=1):\n",
        "        \"\"\"Modify the fake value to ensure uniqueness.\"\"\"\n",
        "        if entity==\"names\":\n",
        "            base=random.choice(self.faker_data['names'])\n",
        "            return base+f\"{string.ascii_lowercase[counter % 26]}\"\n",
        "        elif entity==\"emails\":\n",
        "            base=random.choice(self.faker_data['emails'])\n",
        "            name,domain=base.split('@')\n",
        "            return f\"{name}{counter}@{domain}\"\n",
        "        elif entity==\"url\":\n",
        "            fake_value=original_value\n",
        "            while fake_value in self.used_urls:\n",
        "                ext=random.choice(self.url_extensions)\n",
        "                if not fake_value.endswith(ext):\n",
        "                    fake_value=fake_value+ext\n",
        "            self.used_urls.add(fake_value)\n",
        "            return fake_value\n",
        "        elif entity==\"phone\":\n",
        "            base=random.choice(self.faker_data['phone'])\n",
        "            return f\"{base[:-2]}{counter % 100:02d}\"\n",
        "        elif entity == \"company\":\n",
        "            base=random.choice(self.faker_data['company'])\n",
        "            return f\"{base} Group {counter % 100_000_000 + 1}\"\n",
        "        elif entity == \"credit\":\n",
        "            return f\"{original_value[:-4]}{counter % 10000:04d}\"\n",
        "        else:\n",
        "            return f\"{original_value}-{counter}\"\n",
        "\n",
        "    @time_it\n",
        "    def anonymize_csv(self, input_csv_path):\n",
        "        df = pd.read_csv(input_csv_path)\n",
        "        for entity in df.columns:\n",
        "\n",
        "            if entity not in self.faker_data:\n",
        "                print(f\"Warning: No fake data available for entity type '{entity}' '.\")\n",
        "                continue\n",
        "\n",
        "            df[entity] = df[entity].apply(lambda val: self._get_fake_value(entity, val) if pd.notna(val) else val)\n",
        "\n",
        "        output_csv_path=os.path.join(self.output_dir,f'{self.base_name}_masked.csv')\n",
        "        df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "        combined_mapping = {\n",
        "            \"metadata\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"columns_anonymized\": list(self.forward_mapping.keys()),\n",
        "                \"total_entries\": {\n",
        "                    col: len(self.forward_mapping[col]) for col in self.forward_mapping\n",
        "                }\n",
        "            },\n",
        "            \"forward_mapping\": self.forward_mapping,\n",
        "            \"backward_mapping\": self.backward_mapping,\n",
        "        }\n",
        "        map_path =f'{self.base_name}_mapping.json'\n",
        "        with open(map_path, 'w') as f:\n",
        "            json.dump(combined_mapping, f, indent=2)\n",
        "\n",
        "\n",
        "        # print(f\"Anonymized CSV saved to: {output_csv_path}\")\n",
        "        print(f\" mapping saved to: {map_path}\")\n",
        "\n",
        "\n",
        "    @time_it\n",
        "    def deanonymize_csv(self,anonymized_csv_path,map_path,deanonymized_csv_path):\n",
        "        df = pd.read_csv(anonymized_csv_path)\n",
        "\n",
        "        with open(map_path, 'r') as f:\n",
        "            self.backward_mapping = json.load(f).get(\"backward_mapping\", {})\n",
        "\n",
        "        for col in self.sensitive_columns:\n",
        "            entity= self.entity_column_map.get(col.lower())\n",
        "            if col not in df.columns:\n",
        "                continue\n",
        "            backward_map = self.backward_mapping.get(entity, {})\n",
        "\n",
        "            df[col]=df[col].apply(lambda val:backward_map.get(val,entity) if pd.notna(val) else val )\n",
        "        df.to_csv(deanonymized_csv_path,index=False)\n",
        "        print(f\"Deanonymized CSV saved to: {deanonymized_csv_path}\")\n",
        "    @time_it\n",
        "    def csv_to_sql(self,csv_path,_db_path,table_name):\n",
        "        try:\n",
        "            df=pd.read_csv(csv_path)\n",
        "            conn=sqlite3.connect(_db_path)\n",
        "            df.to_sql(table_name,conn,if_exists='replace',index=False)\n",
        "            conn.close()\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to import CSV: {e}\")\n",
        "\n",
        "    def correct_word(self,word,threshold=65):\n",
        "      valid_list=[company.lower() for company in self.forward_mapping['company'].keys()]\n",
        "      match=process.extractOne(word,valid_list,scorer=fuzz.ratio)\n",
        "      return match[0] if match and match[1]>=threshold else word\n",
        "\n",
        "    def find_and_correct_entities(self,text):\n",
        "      valid_company=[company.lower() for company in self.forward_mapping['company'].keys()]\n",
        "      entities=self.model.predict_entities(text,labels=[\"person\",\"organization\"])\n",
        "\n",
        "      corrected_entities=[]\n",
        "      for ent in entities:\n",
        "        entity_text=ent['text']\n",
        "        start=ent['start']\n",
        "        end=ent['end']\n",
        "        label=ent['label']\n",
        "        if label==\"organization\":\n",
        "          corrected = self.correct_word(entity_text)\n",
        "        else: corrected=entity_text\n",
        "        corrected_entities.append({\n",
        "          'original':entity_text,\n",
        "          'corrected':corrected,\n",
        "          'start':start,\n",
        "          'end':end,\n",
        "          'label':label\n",
        "        })\n",
        "      return corrected_entities\n",
        "\n",
        "    def replace_entities_in_text(self,text,entities):\n",
        "      entities=sorted(entities,key=lambda x:x['start'], reverse=True)\n",
        "      for ent in entities:\n",
        "        text= text[:ent['start']] + ent['corrected'] + text[ent['end']:]\n",
        "      return text\n",
        "\n",
        "file_path = 'companies_100k.csv'\n",
        "masker = DataMaskerCSV(file_path)\n",
        "masker.csv_extraction()\n",
        "\n",
        "entities=masker.find_and_correct_entities(\"companies are accenure and wlrmart and they are doing fine\")\n",
        "print(entities)\n",
        "corrected_text=masker.replace_entities_in_text(\"companies are accenure and wlrmart and they are doing fine\",entities)\n",
        "print(corrected_text)\n"
      ],
      "metadata": {
        "id": "cB1ffo_k39Ra",
        "outputId": "c62e54e9-085f-4d78-bf74-b1f7fe3f99c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "2f8a65d114a04de4acec0eed86b7b29e",
            "a2e58983fb104355a85a9461a3015dfd",
            "104eaed8eaa046d6a28c8f81a02422ab",
            "1fb520d3f37f420da8664b0c0e678985",
            "a43f45d8972b4e9485d2b897b1bfb390",
            "ce60b00fb55141db80d1466f92732745",
            "1dbe5af0e2714999a061fc3c9ceda8e8",
            "c8bab585049e4f468e211a7781f344f3",
            "3c0a11390b694e15ae09b718b10aa54d",
            "d1be730431cf489e8cf340b1ed76b1ff",
            "1400151701d342be8e7465b2dd9bc340"
          ]
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8a65d114a04de4acec0eed86b7b29e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Faker data loaded in 2.107525 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " mapping saved to: companies_100k_mapping.json\n",
            "\n",
            "⏳ Execution time anonymize_csv: 1.747187 seconds\n",
            "\n",
            "⏳ Execution time csv_extraction: 2.853902 seconds\n",
            "[{'original': 'accenure', 'corrected': 'accenture', 'start': 14, 'end': 22, 'label': 'organization'}, {'original': 'wlrmart', 'corrected': 'walmart', 'start': 27, 'end': 34, 'label': 'organization'}]\n",
            "companies are accenure and walmart and they are doing fine\n",
            "companies are accenture and walmart and they are doing fine\n",
            "companies are accenture and walmart and they are doing fine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gliner import GLiNER\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
        "\n",
        "def correct_word(word, valid_list, threshold=65):\n",
        "    match = process.extractOne(word, valid_list, scorer=fuzz.ratio)\n",
        "    return match[0] if match and match[1] >= threshold else word  # fallback if no good match\n",
        "\n",
        "def find_and_correct_entities(text, valid_names, valid_company):\n",
        "    entities = model.predict_entities(text, labels=[\"person\", \"organization\"])\n",
        "\n",
        "    corrected_entities = []\n",
        "\n",
        "    for ent in entities:\n",
        "        entity_text = ent['text']\n",
        "        start = ent['start']\n",
        "        end = ent['end']\n",
        "        label = ent['label']\n",
        "\n",
        "        if label == \"person\":\n",
        "            tokens = entity_text.split()\n",
        "            corrected_tokens = [\n",
        "                correct_word(token.lower(), valid_names).capitalize()\n",
        "                for token in tokens\n",
        "            ]\n",
        "            corrected = \" \".join(corrected_tokens)\n",
        "\n",
        "        elif label == \"organization\":\n",
        "            corrected = correct_word(entity_text.lower(), valid_company).capitalize()\n",
        "\n",
        "        else: corrected = entity_text\n",
        "\n",
        "        corrected_entities.append({\n",
        "            'original': entity_text,\n",
        "            'corrected': corrected,\n",
        "            'start': start,\n",
        "            'end': end,\n",
        "            'label': label\n",
        "        })\n",
        "\n",
        "    return corrected_entities\n",
        "\n",
        "def replace_entities_in_text(text, entities):\n",
        "    entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "\n",
        "    for ent in entities:\n",
        "        text = text[:ent['start']] + ent['corrected'] + text[ent['end']:]\n",
        "    return text\n",
        "\n",
        "def main():\n",
        "  text = \"\"\"Theressa is a manager working for Wiliams. Ruthu Jenkinz is the mother of Fransis Waner and Kaitlyy Meeeers.\n",
        "  Donaa Gavln hasn't been seen for a while now by Nickol. THis is concerning!\"\"\"\n",
        "  valid_names = [name.lower() for name in forward_mapping['names']]\n",
        "  valid_company = [company.lower() for company in forward_mapping['company']]\n",
        "\n",
        "  entities = find_and_correct_entities(text, valid_names, valid_company)\n",
        "  corrected_text = replace_entities_in_text(text, entities)\n",
        "\n",
        "  print(\"\\nCorrected Text:\\n\", corrected_text)\n",
        "\n",
        "main()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "6I7sOeVd29_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwnNlNIEwoZ8"
      },
      "source": [
        "To learn more about accelerating pandas on Colab, see the [10 minute guide](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb) or\n",
        " [US stock market data analysis demo](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_stocks_demo.ipynb)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f8a65d114a04de4acec0eed86b7b29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2e58983fb104355a85a9461a3015dfd",
              "IPY_MODEL_104eaed8eaa046d6a28c8f81a02422ab",
              "IPY_MODEL_1fb520d3f37f420da8664b0c0e678985"
            ],
            "layout": "IPY_MODEL_a43f45d8972b4e9485d2b897b1bfb390"
          }
        },
        "a2e58983fb104355a85a9461a3015dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce60b00fb55141db80d1466f92732745",
            "placeholder": "​",
            "style": "IPY_MODEL_1dbe5af0e2714999a061fc3c9ceda8e8",
            "value": "Fetching 4 files: 100%"
          }
        },
        "104eaed8eaa046d6a28c8f81a02422ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8bab585049e4f468e211a7781f344f3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c0a11390b694e15ae09b718b10aa54d",
            "value": 4
          }
        },
        "1fb520d3f37f420da8664b0c0e678985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1be730431cf489e8cf340b1ed76b1ff",
            "placeholder": "​",
            "style": "IPY_MODEL_1400151701d342be8e7465b2dd9bc340",
            "value": " 4/4 [00:00&lt;00:00, 221.17it/s]"
          }
        },
        "a43f45d8972b4e9485d2b897b1bfb390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce60b00fb55141db80d1466f92732745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbe5af0e2714999a061fc3c9ceda8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8bab585049e4f468e211a7781f344f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0a11390b694e15ae09b718b10aa54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1be730431cf489e8cf340b1ed76b1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1400151701d342be8e7465b2dd9bc340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}